{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Universidad Central**\n",
        "\n",
        "**Maestría en Analítica de Datos**\n",
        "\n",
        "**Big Data**\n",
        "\n",
        "**Estudiante:** Mabel Ayala Meneses\n",
        "\n",
        "**Fecha**: 19/10/2025\n",
        "\n",
        "*Taller de Web Scraping*\n"
      ],
      "metadata": {
        "id": "Jpwp8stdDwc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tome un sitio web de una entidad publica Colombiana (preferiblemente un ministerio o superintendencia) y aplique web scraping para:\n",
        "\n",
        "1. Escanear las paginas del sitio de la entidad y descargue archivos PDF's sobre normatividades.\n",
        "2. Extraiga el texto de los pdf (extracción normal o con OCR).\n",
        "3. Cree un archivo Json por cada PDF donde se tengan los campos: \"Nombre archivo\", \"texto\", \"fecha\"\n",
        "subir los archivos Json a una colección en mongo DB"
      ],
      "metadata": {
        "id": "beVabjzIEhSN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csnfDxrKDl2D"
      },
      "outputs": [],
      "source": [
        "# habilitamos drive de google desde colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Librerías"
      ],
      "metadata": {
        "id": "xoeBF36wSeJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 lxml\n",
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiUIzVhGSZeG",
        "outputId": "9cd0ebb3-efb8-4495-a03f-2ff9af2880cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.23)\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20250506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 lxml pdfminer.six pymongo\n",
        "# (Opcional OCR)\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install poppler-utils tesseract-ocr\n",
        "!pip install pdf2image pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAGJy2NBJ-ED",
        "outputId": "72526280-6c04-4652-87fc-b0f9444f1776"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.23)\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo, pdfminer.six\n",
            "Successfully installed dnspython-2.8.0 pdfminer.six-20250506 pymongo-4.15.3\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.11_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.11) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.11) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pdf2image) (11.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"MONGO_URI\"]  = \"mongodb+srv://mayala:mayala123@mayala.y4cqo9f.mongodb.net/?retryWrites=true&w=majority&appName=mayala\"\n",
        "os.environ[\"MONGO_DB\"]   = \"MININTERIOR\"\n",
        "os.environ[\"MONGO_COLL\"] = \"NORMATIVIDAD\""
      ],
      "metadata": {
        "id": "Sj2AtbD6KAkl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Scraper (Normograma MinInterior) -> PDFs -> JSON (+ opcional MongoDB)\n",
        "# Librerías: requests, bs4, lxml, pdfminer.six, (opcional) pdf2image+pytesseract, pymongo\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import hashlib\n",
        "import argparse\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Optional, Tuple\n",
        "from urllib.parse import urljoin\n",
        "from datetime import datetime\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "# -------- OCR opcional: si no están instalados, no se usa y no rompe --------\n",
        "USE_OCR = True\n",
        "try:\n",
        "    from pdf2image import convert_from_path\n",
        "    import pytesseract\n",
        "except Exception:\n",
        "    USE_OCR = False\n",
        "\n",
        "# -------- Mongo opcional: si no defines MONGO_URI, no inserta en Mongo --------\n",
        "from pymongo import MongoClient\n",
        "from pymongo.errors import PyMongoError\n",
        "MONGO_URI  = os.environ.get(\"MONGO_URI\")        # Si no existe, se desactiva Mongo\n",
        "MONGO_DB   = os.environ.get(\"MONGO_DB\", \"MININTERIOR\")\n",
        "MONGO_COLL = os.environ.get(\"MONGO_COLL\", \"NORMATIVIDAD\")\n",
        "ENABLE_MONGO = bool(MONGO_URI)\n",
        "\n",
        "# ================== CONFIG ==================\n",
        "DEST_DIR = \"/content/drive/MyDrive/Big data/Taller 1\"  # <-- AJUSTA si quieres\n",
        "os.makedirs(DEST_DIR, exist_ok=True)\n",
        "\n",
        "BASE_URL = \"https://www.mininterior.gov.co/normatividad/?filter=true&page={page}\"\n",
        "USER_AGENT = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119 Safari/537.36\"\n",
        "HEADERS = {\"User-Agent\": USER_AGENT}\n",
        "TIMEOUT = 25\n",
        "PAUSE   = 0.8  # cortesía entre requests\n",
        "\n",
        "# Límites\n",
        "MAX_PDFS  = 50   # Límite global de PDFs a extraer\n",
        "MAX_PAGES = 60   # Límite de páginas HTML a visitar\n",
        "VERBOSE   = True\n",
        "\n",
        "# ================== SESIÓN CON REINTENTOS + CERTIFI ==================\n",
        "import certifi\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "from requests.exceptions import SSLError, RequestException\n",
        "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
        "\n",
        "SESSION = requests.Session()\n",
        "retry = Retry(\n",
        "    total=3,\n",
        "    connect=3,\n",
        "    read=3,\n",
        "    backoff_factor=0.6,   # 0.6s, 1.2s, 2.4s...\n",
        "    status_forcelist=(429, 500, 502, 503, 504),\n",
        "    allowed_methods=frozenset([\"GET\", \"HEAD\"]),\n",
        ")\n",
        "adapter = HTTPAdapter(max_retries=retry)\n",
        "SESSION.mount(\"https://\", adapter)\n",
        "SESSION.mount(\"http://\", adapter)\n",
        "\n",
        "HEADERS.update({\n",
        "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
        "    \"Accept-Language\": \"es-CO,es;q=0.9,en;q=0.8\",\n",
        "    \"Cache-Control\": \"no-cache\",\n",
        "    \"Pragma\": \"no-cache\",\n",
        "})\n",
        "VERIFY_PATH = certifi.where()\n",
        "\n",
        "# ================== DATA MODEL ==================\n",
        "@dataclass\n",
        "class DocRecord:\n",
        "    titulo: str\n",
        "    url_pdf: str\n",
        "    fuente: str\n",
        "    fecha_captura: str\n",
        "    archivo: str\n",
        "    sha1: str\n",
        "    texto: str\n",
        "    ocr_usado: bool\n",
        "\n",
        "# ================== UTILS ==================\n",
        "def norm(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
        "\n",
        "def safe_name(name: str) -> str:\n",
        "    name = re.sub(r\"[^\\w\\-.]+\", \"_\", name)\n",
        "    return name[:150]\n",
        "\n",
        "def sha1_file(path: str) -> str:\n",
        "    h = hashlib.sha1()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "# ================== WEB LAYER ==================\n",
        "def fetch_html(url: str) -> Optional[BeautifulSoup]:\n",
        "    try:\n",
        "        # Intento normal: validar SSL con bundle de certifi\n",
        "        r = SESSION.get(url, headers=HEADERS, timeout=TIMEOUT, verify=VERIFY_PATH, allow_redirects=True)\n",
        "        r.raise_for_status()\n",
        "        return BeautifulSoup(r.text, \"lxml\")\n",
        "\n",
        "    except SSLError as e:\n",
        "        # Fallback único: desactivar verify solo para este request\n",
        "        print(f\"[WARN] SSL error con verificación. Reintentando sin verify: {e}\")\n",
        "        try:\n",
        "            requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\n",
        "            r = SESSION.get(url, headers=HEADERS, timeout=TIMEOUT, verify=False, allow_redirects=True)\n",
        "            r.raise_for_status()\n",
        "            return BeautifulSoup(r.text, \"lxml\")\n",
        "        except Exception as e2:\n",
        "            print(f\"[WARN] HTML fetch failed (sin verify): {e2} @ {url}\")\n",
        "            return None\n",
        "\n",
        "    except RequestException as e:\n",
        "        print(f\"[WARN] HTML fetch failed: {e} @ {url}\")\n",
        "        return None\n",
        "\n",
        "def collect_pdf_links(pages: List[int]) -> List[Tuple[str, str]]:\n",
        "    links, seen = [], set()\n",
        "    for p in pages[:MAX_PAGES]:\n",
        "        url = BASE_URL.format(page=p)\n",
        "        soup = fetch_html(url)\n",
        "        if not soup:\n",
        "            time.sleep(PAUSE)\n",
        "            continue\n",
        "        for a in soup.select(\"a\"):\n",
        "            href = (a.get(\"href\") or \"\").strip()\n",
        "            if href.lower().endswith(\".pdf\"):\n",
        "                abs_url = urljoin(url, href)\n",
        "                if abs_url in seen:\n",
        "                    continue\n",
        "                seen.add(abs_url)\n",
        "                title = norm(a.get_text()) or os.path.basename(abs_url)\n",
        "                links.append((title, abs_url))\n",
        "        if len(links) >= MAX_PDFS:\n",
        "            break\n",
        "        time.sleep(PAUSE)\n",
        "    return links[:MAX_PDFS]\n",
        "\n",
        "# ================== FILES & PARSING ==================\n",
        "def download_pdf(title: str, pdf_url: str) -> Optional[str]:\n",
        "    filename = safe_name(f\"{title}.pdf\")\n",
        "    path = os.path.join(DEST_DIR, filename)\n",
        "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
        "        if VERBOSE: print(f\"  • Exists: {filename}\")\n",
        "        return path\n",
        "    try:\n",
        "        with SESSION.get(pdf_url, headers=HEADERS, timeout=60, stream=True, verify=VERIFY_PATH) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(path, \"wb\") as f:\n",
        "                for chunk in r.iter_content(chunk_size=1 << 16):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "        if VERBOSE: print(f\"  ✓ Downloaded: {filename}\")\n",
        "        return path\n",
        "    except SSLError as e:\n",
        "        print(f\"[WARN] SSL al descargar {pdf_url}. Reintentando sin verify: {e}\")\n",
        "        try:\n",
        "            requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\n",
        "            with SESSION.get(pdf_url, headers=HEADERS, timeout=60, stream=True, verify=False) as r:\n",
        "                r.raise_for_status()\n",
        "                with open(path, \"wb\") as f:\n",
        "                    for chunk in r.iter_content(chunk_size=1 << 16):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "            if VERBOSE: print(f\"  ✓ Downloaded (sin verify): {filename}\")\n",
        "            return path\n",
        "        except Exception as e2:\n",
        "            print(f\"[WARN] PDF download failed (sin verify) {pdf_url}: {e2}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] PDF download failed ({pdf_url}): {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_text_pdfminer(path: str) -> str:\n",
        "    try:\n",
        "        return norm(extract_text(path) or \"\")\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] pdfminer failed for {os.path.basename(path)}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def extract_text_ocr(path: str) -> str:\n",
        "    if not USE_OCR:\n",
        "        return \"\"\n",
        "    try:\n",
        "        pages = convert_from_path(path)\n",
        "        texts = [pytesseract.image_to_string(img, lang=\"spa+eng\") for img in pages]\n",
        "        return norm(\"\\n\".join(texts))\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] OCR failed for {os.path.basename(path)}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# ================== MONGODB ==================\n",
        "def mongo_client() -> Optional[MongoClient]:\n",
        "    if not ENABLE_MONGO:\n",
        "        return None\n",
        "    return MongoClient(MONGO_URI)\n",
        "\n",
        "def upsert_document(rec: DocRecord) -> Optional[str]:\n",
        "    if not ENABLE_MONGO:\n",
        "        return None\n",
        "    try:\n",
        "        client = mongo_client()\n",
        "        coll = client[MONGO_DB][MONGO_COLL]\n",
        "        payload = asdict(rec)\n",
        "        result = coll.update_one({\"sha1\": rec.sha1}, {\"$set\": payload}, upsert=True)\n",
        "        return str(result.upserted_id) if result.upserted_id else None\n",
        "    except PyMongoError as e:\n",
        "        print(f\"[WARN] MongoDB error: {e}\")\n",
        "        return None\n",
        "\n",
        "# ================== PIPELINE ==================\n",
        "def process_link(title: str, pdf_url: str) -> Optional[DocRecord]:\n",
        "    local_pdf = download_pdf(title, pdf_url)\n",
        "    if not local_pdf:\n",
        "        return None\n",
        "\n",
        "    digest = sha1_file(local_pdf)\n",
        "\n",
        "    text = extract_text_pdfminer(local_pdf)\n",
        "    used_ocr = False\n",
        "    if len(text) < 200:  # fallback si casi no hay texto\n",
        "        ocr_text = extract_text_ocr(local_pdf)\n",
        "        if len(ocr_text) > len(text):\n",
        "            text = ocr_text\n",
        "            used_ocr = True\n",
        "\n",
        "    return DocRecord(\n",
        "        titulo=title,\n",
        "        url_pdf=pdf_url,\n",
        "        fuente=\"MinInterior Normatividad\",\n",
        "        fecha_captura=datetime.utcnow().isoformat() + \"Z\",\n",
        "        archivo=os.path.basename(local_pdf),\n",
        "        sha1=digest,\n",
        "        texto=text,\n",
        "        ocr_usado=used_ocr,\n",
        "    )\n",
        "\n",
        "def save_json(rec: DocRecord) -> str:\n",
        "    out_name = os.path.splitext(rec.archivo)[0] + \".json\"\n",
        "    out_path = os.path.join(DEST_DIR, out_name)\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(asdict(rec), f, ensure_ascii=False, indent=2)\n",
        "    return out_path\n",
        "\n",
        "def run(pages: List[int], limit: int) -> None:\n",
        "    links = collect_pdf_links(pages)\n",
        "    print(f\"Encontrados {len(links)} PDFs.\")\n",
        "    processed = 0\n",
        "    for title, url in links:\n",
        "        if processed >= limit:\n",
        "            break\n",
        "        print(f\"\\n→ Procesando: {title}\")\n",
        "        rec = process_link(title, url)\n",
        "        if not rec:\n",
        "            continue\n",
        "        json_path = save_json(rec)\n",
        "        print(f\"  • JSON guardado: {os.path.basename(json_path)}  | OCR: {rec.ocr_usado}\")\n",
        "        ins_id = upsert_document(rec)\n",
        "        if ins_id:\n",
        "            print(f\"  • Insertado en MongoDB _id={ins_id}\")\n",
        "        processed += 1\n",
        "        time.sleep(1.0)\n",
        "\n",
        "    print(f\"\\nListo. Documentos procesados: {processed}\")\n",
        "\n",
        "# ================== CLI (compatible con Colab/Jupyter) ==================\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Scrape MinInterior PDFs → text → JSON → (opcional) MongoDB\",\n",
        "        add_help=True,\n",
        "    )\n",
        "    parser.add_argument(\"--pages\", type=str, default=\"1-2\",\n",
        "                        help=\"Rango de páginas, ej. '1-3' o lista '1,2,3'\")\n",
        "    parser.add_argument(\"--limit\", type=int, default=10,\n",
        "                        help=\"Número máximo de PDFs a procesar\")\n",
        "    # Ignora los argumentos desconocidos que inyecta Jupyter/Colab (p.ej. -f ...)\n",
        "    args, _ = parser.parse_known_args()\n",
        "    return args\n",
        "\n",
        "def parse_pages(s: str) -> List[int]:\n",
        "    s = s.strip()\n",
        "    if \"-\" in s:\n",
        "        a, b = s.split(\"-\", 1)\n",
        "        return list(range(int(a), int(b) + 1))\n",
        "    return [int(x) for x in s.split(\",\") if x.strip()]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    pages = parse_pages(args.pages)\n",
        "    run(pages=pages, limit=args.limit)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07YPx-rzK5-Z",
        "outputId": "96991f80-8941-4cd7-d5c5-09f7eca13939"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /normatividad/?filter=true&page=1\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /normatividad/?filter=true&page=1\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /normatividad/?filter=true&page=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] SSL error con verificación. Reintentando sin verify: HTTPSConnectionPool(host='www.mininterior.gov.co', port=443): Max retries exceeded with url: /normatividad/?filter=true&page=1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /normatividad/?filter=true&page=2\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /normatividad/?filter=true&page=2\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /normatividad/?filter=true&page=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] SSL error con verificación. Reintentando sin verify: HTTPSConnectionPool(host='www.mininterior.gov.co', port=443): Max retries exceeded with url: /normatividad/?filter=true&page=2 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2025/04/28-abr-25-carta-trato-digno-v7.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontrados 17 PDFs.\n",
            "\n",
            "→ Procesando: Carta de trato digno al ciudadano\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2025/04/28-abr-25-carta-trato-digno-v7.pdf\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2025/04/28-abr-25-carta-trato-digno-v7.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] SSL al descargar https://www.mininterior.gov.co/wp-content/uploads/2025/04/28-abr-25-carta-trato-digno-v7.pdf. Reintentando sin verify: HTTPSConnectionPool(host='www.mininterior.gov.co', port=443): Max retries exceeded with url: /wp-content/uploads/2025/04/28-abr-25-carta-trato-digno-v7.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)')))\n",
            "  ✓ Downloaded (sin verify): Carta_de_trato_digno_al_ciudadano.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30572905.py:244: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  fecha_captura=datetime.utcnow().isoformat() + \"Z\",\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  • JSON guardado: Carta_de_trato_digno_al_ciudadano.json  | OCR: False\n",
            "  • Insertado en MongoDB _id=68f54ad242457f3cbdba9cb7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2025/10/resolucion-numero-cocorpun01782024-de-21-de-octubre-de-2024.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "→ Procesando: Documento\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2025/10/resolucion-numero-cocorpun01782024-de-21-de-octubre-de-2024.pdf\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2025/10/resolucion-numero-cocorpun01782024-de-21-de-octubre-de-2024.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] SSL al descargar https://www.mininterior.gov.co/wp-content/uploads/2025/10/resolucion-numero-cocorpun01782024-de-21-de-octubre-de-2024.pdf. Reintentando sin verify: HTTPSConnectionPool(host='www.mininterior.gov.co', port=443): Max retries exceeded with url: /wp-content/uploads/2025/10/resolucion-numero-cocorpun01782024-de-21-de-octubre-de-2024.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)')))\n",
            "  ✓ Downloaded (sin verify): Documento.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30572905.py:244: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  fecha_captura=datetime.utcnow().isoformat() + \"Z\",\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  • JSON guardado: Documento.json  | OCR: False\n",
            "  • Insertado en MongoDB _id=68f54ad942457f3cbdba9cb8\n",
            "\n",
            "→ Procesando: Documento\n",
            "  • Exists: Documento.pdf\n",
            "  • JSON guardado: Documento.json  | OCR: False\n",
            "\n",
            "→ Procesando: Documento\n",
            "  • Exists: Documento.pdf\n",
            "  • JSON guardado: Documento.json  | OCR: False\n",
            "\n",
            "→ Procesando: Documento\n",
            "  • Exists: Documento.pdf\n",
            "  • JSON guardado: Documento.json  | OCR: False\n",
            "\n",
            "→ Procesando: Documento\n",
            "  • Exists: Documento.pdf\n",
            "  • JSON guardado: Documento.json  | OCR: False\n",
            "\n",
            "→ Procesando: Documento\n",
            "  • Exists: Documento.pdf\n",
            "  • JSON guardado: Documento.json  | OCR: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2022/09/2022-09-22_DOCUMENTO-POLITICA-PUBLICA-DE-PARTICIPACION-CIUDADANA-VERSION-FINAL-AJUSTADA-27092022.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "→ Procesando: Otras Políticas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2022/09/2022-09-22_DOCUMENTO-POLITICA-PUBLICA-DE-PARTICIPACION-CIUDADANA-VERSION-FINAL-AJUSTADA-27092022.pdf\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2022/09/2022-09-22_DOCUMENTO-POLITICA-PUBLICA-DE-PARTICIPACION-CIUDADANA-VERSION-FINAL-AJUSTADA-27092022.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] SSL al descargar https://www.mininterior.gov.co/wp-content/uploads/2022/09/2022-09-22_DOCUMENTO-POLITICA-PUBLICA-DE-PARTICIPACION-CIUDADANA-VERSION-FINAL-AJUSTADA-27092022.pdf. Reintentando sin verify: HTTPSConnectionPool(host='www.mininterior.gov.co', port=443): Max retries exceeded with url: /wp-content/uploads/2022/09/2022-09-22_DOCUMENTO-POLITICA-PUBLICA-DE-PARTICIPACION-CIUDADANA-VERSION-FINAL-AJUSTADA-27092022.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)')))\n",
            "  ✓ Downloaded (sin verify): Otras_Políticas.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P341' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P347' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P353' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P396' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P407' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P418' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P429' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P438' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P444' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P450' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P456' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P462' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P468' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P474' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P480' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P486' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P492' is an invalid float value\n",
            "/tmp/ipython-input-30572905.py:244: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  fecha_captura=datetime.utcnow().isoformat() + \"Z\",\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  • JSON guardado: Otras_Políticas.json  | OCR: False\n",
            "  • Insertado en MongoDB _id=68f54af542457f3cbdba9cb9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2022/09/ir-a-terminos-y-condiciones-e-uso.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "→ Procesando: Terminos y condiciones\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2022/09/ir-a-terminos-y-condiciones-e-uso.pdf\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2022/09/ir-a-terminos-y-condiciones-e-uso.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] SSL al descargar https://www.mininterior.gov.co/wp-content/uploads/2022/09/ir-a-terminos-y-condiciones-e-uso.pdf. Reintentando sin verify: HTTPSConnectionPool(host='www.mininterior.gov.co', port=443): Max retries exceeded with url: /wp-content/uploads/2022/09/ir-a-terminos-y-condiciones-e-uso.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)')))\n",
            "  ✓ Downloaded (sin verify): Terminos_y_condiciones.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30572905.py:244: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  fecha_captura=datetime.utcnow().isoformat() + \"Z\",\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  • JSON guardado: Terminos_y_condiciones.json  | OCR: False\n",
            "  • Insertado en MongoDB _id=68f54afb42457f3cbdba9cba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2022/07/politica_de_tratamiento_de_datos_personales.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "→ Procesando: Datos personales\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2022/07/politica_de_tratamiento_de_datos_personales.pdf\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)'))': /wp-content/uploads/2022/07/politica_de_tratamiento_de_datos_personales.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] SSL al descargar https://www.mininterior.gov.co/wp-content/uploads/2022/07/politica_de_tratamiento_de_datos_personales.pdf. Reintentando sin verify: HTTPSConnectionPool(host='www.mininterior.gov.co', port=443): Max retries exceeded with url: /wp-content/uploads/2022/07/politica_de_tratamiento_de_datos_personales.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)')))\n",
            "  ✓ Downloaded (sin verify): Datos_personales.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30572905.py:244: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  fecha_captura=datetime.utcnow().isoformat() + \"Z\",\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  • JSON guardado: Datos_personales.json  | OCR: True\n",
            "  • Insertado en MongoDB _id=68f54b7642457f3cbdba9cc0\n",
            "\n",
            "Listo. Documentos procesados: 10\n"
          ]
        }
      ]
    }
  ]
}